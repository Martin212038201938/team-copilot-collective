# ğŸ¤– AI-Powered Content Generator

Automatische Generierung von **professionell tiefgehenden, fachlich exzellenten** Wissensseiten aus YouTube-Transkripten oder Texten unter Verwendung von OpenAI GPT-4.

## ğŸš€ NEU: Professionelle QualitÃ¤t statt Generischer Content

**Das wurde verbessert (Januar 2026):**

Der Content Generator wurde grundlegend Ã¼berarbeitet, um Artikel zu erstellen, die sich **fundamental von generischem AI-Content unterscheiden**:

### Was ist anders?

**VORHER (Alte Version):**
- âŒ 2.000-2.500 WÃ¶rter, oft zu kurz und oberflÃ¤chlich
- âŒ Generische Phrasen und Marketing-Sprache
- âŒ Fehlender Fokus auf das Hauptthema
- âŒ Wenig konkrete Use Cases
- âŒ OberflÃ¤chliche technische Details
- âŒ 7-9 FAQs mit kurzen Antworten

**NACHHER (Neue Version):**
- âœ… 3.000-5.000 WÃ¶rter mit substantiellem Inhalt
- âœ… Professionelle Sprache, technische PrÃ¤zision
- âœ… Laser-Fokus auf das identifizierte Hauptthema
- âœ… MINIMUM 3-5 konkrete Use Cases pro Sektion
- âœ… Technische Tiefe: APIs, Architekturen, Konfigurationen
- âœ… 10-15 umfassende FAQs (80-150 WÃ¶rter pro Antwort)
- âœ… **NEU**: Automatische Recherche aktueller Informationen (2025)
- âœ… **NEU**: Automatische QualitÃ¤tsprÃ¼fung (LÃ¤nge, Struktur, generische Phrasen)
- âœ… **NEU**: Optimiert fÃ¼r Zitierbarkeit durch ChatGPT, Gemini, Claude

### Warum diese Ã„nderungen?

Artikel mÃ¼ssen sich von der Flut generischer AI-Inhalte abheben durch:
1. **Fachliche Exzellenz**: Technische Tiefe, die Experten schÃ¤tzen
2. **Praxisrelevanz**: Konkrete Use Cases fÃ¼r den beruflichen Alltag
3. **AktualitÃ¤t**: Recherchierte Informationen zu neuesten Features
4. **LLM-Zitierbarkeit**: Optimiert fÃ¼r AI Answer Engines (ChatGPT, Perplexity, etc.)

## âœ¨ Features

- **ğŸš€ Vollautomatisch**: Aus Transkript wird komplette TSX-Komponente
- **ğŸ¯ Professionelle Tiefe**: KEIN generischer Content - fachlich tiefgehende Artikel mit 3.000-5.000 WÃ¶rtern
- **ğŸ” Intelligente Recherche**: Automatische Integration aktueller Informationen (Stand 2025)
- **ğŸ’¼ Praxisrelevanz**: Minimum 3-5 Use Cases pro Sektion fÃ¼r den beruflichen Alltag
- **ğŸ“Š LLM-optimiert**: Dual Schema.org (Article + FAQPage), optimal fÃ¼r Zitierbarkeit durch ChatGPT, Gemini, etc.
- **âš¡ Performance**: Optimierte React-Komponenten, < 2.5s Ladezeit
- **ğŸ”’ Sicher**: API Key in .env.local, automatischer Kill-Switch
- **ğŸ“ E-E-A-T Excellence**: Experience, Expertise, Authoritativeness, Trustworthiness auf professionellem Niveau
- **âœ… QualitÃ¤tssicherung**: Automatische Checks fÃ¼r LÃ¤nge, Struktur und generische Phrasen
- **ğŸ¨ Design**: Tailwind CSS, responsive, visuelle Hierarchie
- **ğŸ“… Publishing-Ready**: Automatisch scheduled fÃ¼r nÃ¤chsten Dienstag

## ğŸ› ï¸ Setup

### 1. API Key konfigurieren

Der OpenAI API Key ist bereits in `.env.local` gespeichert:

```bash
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o
OPENAI_MAX_TOKENS=16000
OPENAI_TEMPERATURE=0.7
```

**WICHTIG**: `.env.local` ist in `.gitignore` und wird NICHT ins Repository committed.

### ğŸ”’ Automatischer Kill-Switch

**Zum Schutz vor Ã¼bermÃ¤ÃŸigen Kosten durch Fehler oder Endlosschleifen:**

- **TÃ¤gliches Limit**: 3,00 EUR
- **Max. Requests/Minute**: 10 (Schutz vor Schleifen)
- **Max. Requests/Stunde**: 50 (Schutz vor Massenverarbeitung)

Bei Ãœberschreitung: **Sofortiger Stop aller API-Anfragen**

```bash
# Kosten-Statistiken anzeigen
npm run cost:stats

# Tracking wird automatisch durchgefÃ¼hrt
# Automatischer Reset um Mitternacht
```

**Siehe [SECURITY.md](../SECURITY.md) fÃ¼r Details.**

### 2. Dependencies

Dependencies sind bereits installiert via `npm install`:

- `openai` - OpenAI API Client
- `dotenv` - Environment Variables

## ğŸ“– Verwendung

### Option 1: Interaktiver Modus (empfohlen)

```bash
npm run generate:interactive
```

Das Script fÃ¼hrt Sie Schritt-fÃ¼r-Schritt durch:

1. Transkript-Quelle wÃ¤hlen (Datei oder direktes EinfÃ¼gen)
2. Optional: ZusÃ¤tzliche Anweisungen eingeben
3. Automatische Generierung mit OpenAI GPT-4
4. Automatisches Speichern als TSX + Draft JSON

**Beispiel-Session:**

```bash
$ npm run generate:interactive

ğŸ¨ AI Content Generator - Interactive Mode

Transkript-Datei (oder "paste" fÃ¼r direktes EinfÃ¼gen): transcripts/teams-tutorial.txt

ZusÃ¤tzliche Anweisungen (optional, Enter Ã¼berspringen): Fokus auf Collaboration Features

Aktuelle Informationen recherchieren? (j/N): j

ğŸ” Recherchiere aktuelle Informationen zum Thema...
ğŸ“Œ Thema:
âœ… Recherche abgeschlossen
ğŸ“Š Tokens verwendet: 1543

ğŸ¤– Generiere professionell tiefgehende Wissensseite mit OpenAI GPT-4...
ğŸ“Š Transkript-LÃ¤nge: 12543 Zeichen
ğŸ“ Prompt-LÃ¤nge: 48234 Zeichen
â³ Bitte warten, dies kann 60-120 Sekunden dauern (umfangreicher Artikel)...

âœ… Content erfolgreich generiert!
ğŸ“Š Generierte Code-LÃ¤nge: 26847 Zeichen
ğŸ’° Tokens verwendet: 18234
   - Prompt: 10234
   - Completion: 8000

ğŸ“Š QUALITÃ„TSPRÃœFUNG:
âœ… LÃ¤nge: 3842 WÃ¶rter (ausgezeichnet!)
âœ… Alle QualitÃ¤tschecks bestanden!

ğŸ“‹ Generierte Metadaten:
   Titel: Microsoft Teams Collaboration - Professioneller Praxis-Guide
   Slug: microsoft-teams-collaboration-praxis-guide
   Lesezeit: 14 Minuten
   Publikation: 07.01.2026

âœ… TSX gespeichert: src/pages/MicrosoftTeamsCollaborationGuide.tsx
âœ… Draft JSON gespeichert: content/drafts/microsoft-teams-collaboration-guide.json
âœ… Public Draft gespeichert: public/content/drafts/microsoft-teams-collaboration-guide.json

ğŸ‰ Content erfolgreich generiert und gespeichert!

NÃ¤chste Schritte:
1. ÃœberprÃ¼fe die generierte Komponente
2. Teste die Vorschau im Admin-Dashboard
3. Passe bei Bedarf Details an
4. Commit und Push zum Repository
```

### Option 2: CLI-Modus mit Datei

```bash
npm run generate transcripts/mein-transkript.txt
```

Oder mit zusÃ¤tzlichen Anweisungen:

```bash
npm run generate transcripts/mein-transkript.txt "Fokus auf Enterprise Features"
```

### Option 3: Direkter Node-Aufruf

```bash
node scripts/generate-content.js transcripts/mein-transkript.txt
node scripts/generate-content.js --interactive
```

## ğŸ“‚ Eingabe-Formate

Das Script akzeptiert:

- **Plain Text** (.txt)
- **Markdown** (.md)
- **SRT Untertitel** (.srt)
- **VTT Untertitel** (.vtt)
- **Direktes EinfÃ¼gen** (im interaktiven Modus)

**Empfohlene Transkript-Struktur:**

```
[Video Titel]
[Datum/Quelle]

Transkript:
...Ihr Transkript-Text hier...

Wichtige Punkte:
- Punkt 1
- Punkt 2
```

## ğŸ¨ Was wird generiert?

### 1. TSX-Komponente (`src/pages/[ComponentName].tsx`)

VollstÃ¤ndige React/TypeScript Komponente mit:

- âœ… Alle notwendigen Imports (ContentLayout, SEOHead, etc.)
- âœ… Table of Contents (7-9 Sektionen)
- âœ… Dual Schema.org Markup (Article + FAQPage)
- âœ… SEO Meta-Tags (Title, Description, Keywords, Canonical)
- âœ… 8-12 Minuten Lesezeit (~2.000-3.500 WÃ¶rter)
- âœ… FAQ-Sektion mit 8-10 Fragen
- âœ… Visuelle Elemente (Cards, Gradient-Boxen, Icons)
- âœ… Best Practices, Do's/Don'ts
- âœ… Praxis-Beispiele und Schritt-fÃ¼r-Schritt Anleitungen
- âœ… Call-to-Action am Ende

### 2. Draft JSON (`content/drafts/[slug].json`)

Metadaten fÃ¼r das Redaktionssystem:

```json
{
  "id": "microsoft-teams-guide",
  "title": "Microsoft Teams - Der komplette Guide",
  "description": "...",
  "content": "IMPORTED FROM TSX FILE",
  "contentType": "code",
  "codeFileName": "MicrosoftTeamsGuide.tsx",
  "publishDate": "2025-11-19T09:00:00.000Z",
  "author": "martin-lang",
  "category": "Microsoft 365",
  "slug": "microsoft-teams-guide",
  "keywords": [...],
  "readTime": "9 Minuten",
  "icon": "ğŸ¤–",
  "status": "scheduled"
}
```

### 3. Public Draft (`public/content/drafts/[slug].json`)

Kopie fÃ¼r Frontend-Zugriff im Admin-Dashboard.

## ğŸ¯ QualitÃ¤tskriterien - PROFESSIONELL TIEFGEHEND

Das verbesserte Script erstellt Artikel, die sich fundamental von generischem AI-Content unterscheiden:

### 1. THEMATISCHER FOKUS
- âœ… PrÃ¤zise Identifikation des Hauptthemas aus dem Transkript
- âœ… Artikel konzentriert sich ausschlieÃŸlich auf das Kernthema
- âœ… Jede Sektion beleuchtet das Hauptthema aus anderem Blickwinkel
- âŒ KEINE Abschweifungen zu tangentialen Themen

### 2. PROFESSIONELLE TIEFE
- âœ… MINIMUM 400-600 WÃ¶rter pro Hauptsektion
- âœ… Technische Details, API-Namen, Versionsangaben
- âœ… ErklÃ¤rung von "Warum" und "Wie", nicht nur "Was"
- âœ… Architektur-VerstÃ¤ndnis und technische ZusammenhÃ¤nge
- âŒ KEINE Marketing-Phrasen oder oberflÃ¤chliche Beschreibungen

### 3. PRAXISRELEVANZ
- âœ… MINIMUM 3-5 konkrete Use Cases pro Hauptsektion
- âœ… Branchenspezifische Beispiele (Finance, Healthcare, Manufacturing)
- âœ… Rollenspezifische Szenarien (IT-Admin, Developer, Business User)
- âœ… Schritt-fÃ¼r-Schritt Anleitungen mit konkreten Schritten
- âœ… Echte Prompt-Beispiele, Code-Snippets, Konfigurationen
- âœ… Messbare Ergebnisse (ROI, Zeitersparnis, Effizienz)

### 4. SUBSTANTIELLE LÃ„NGE
- âœ… Ziel: 3.000-5.000 WÃ¶rter (10-15 Minuten Lesezeit)
- âœ… QualitÃ¤t und Tiefe Ã¼ber KÃ¼rze
- âœ… FAQ-Sektion: 10-15 Fragen mit jeweils 80-150 WÃ¶rtern
- âŒ KEINE VerkÃ¼rzungen, die Artikel generisch machen

### 5. LLM-ZITIERBARKEIT
- âœ… Extractable Facts: Jede Information als eigenstÃ¤ndiger Fakt
- âœ… Definitive Antworten auf spezifische Fragen
- âœ… Strukturierte Daten: Listen, Tabellen, Vergleichsmatrizen
- âœ… Zitierbare Aussagen fÃ¼r ChatGPT, Gemini, Claude
- âœ… Entity-reich: VollstÃ¤ndige Namen statt Pronomen

### 6. PROFESSIONELLE VERGLEICHE
- âœ… Alternativen und Konkurrenzprodukte diskutiert
- âœ… Ehrliche Bewertung von Pros & Cons
- âœ… Klare Guidance: Wann nutzen, wann nicht
- âœ… Integrations- und Migrations-Ãœberlegungen

### 7. AKTUELLE RECHERCHE
- âœ… Optional: Automatische Recherche aktueller Informationen (2025)
- âœ… Neueste Features, Updates, Beta-Funktionen
- âœ… Verweise auf offizielle Quellen und Roadmaps

### 8. AUTOMATISCHE QUALITÃ„TSPRÃœFUNG
- âœ… Minimum 2.500 WÃ¶rter (Warnung < 3.000)
- âœ… Check auf generische AI-Phrasen
- âœ… Validierung von Schema.org Markup
- âœ… PrÃ¼fung von FAQ-Sektion und Table of Contents

### 9. E-E-A-T EXCELLENCE
- **Experience**: "In Projekten mit Enterprise-Kunden...", spezifische Zahlen
- **Expertise**: Technische Tiefe, API-Details, Performance-Metriken
- **Authoritativeness**: Microsoft Docs, Whitepapers, Case Studies
- **Trustworthiness**: Transparente Limitationen, bekannte Issues

### 10. VISUELLE HIERARCHIE
- Gradient-Boxen fÃ¼r wichtige Konzepte
- Border-left Highlights fÃ¼r Callouts
- Cards fÃ¼r Use Cases und Vergleiche
- Code-BlÃ¶cke mit Syntax-Highlighting
- Responsive Design mit Tailwind CSS

## ğŸ’° Kosten

**OpenAI GPT-4o Pricing (Stand Januar 2025):**

- Input: $2.50 per 1M tokens
- Output: $10.00 per 1M tokens

**Typische Kosten pro generierter Seite (MIT Recherche):**

- Research: ~1.500 tokens = ~$0.02
- Prompt: ~10.000 tokens = ~$0.025
- Completion: ~8.000 tokens = ~$0.08
- **Total: ~$0.125 pro Seite**

**Typische Kosten pro generierter Seite (OHNE Recherche):**

- Prompt: ~10.000 tokens = ~$0.025
- Completion: ~8.000 tokens = ~$0.08
- **Total: ~$0.105 pro Seite**

**Bei 10 Seiten/Monat: ~$1.25/Monat (mit Recherche)**

**Hinweis**: Die hÃ¶heren Kosten reflektieren die deutlich verbesserte QualitÃ¤t:
- 2-3x lÃ¤ngerer Content (3.000-5.000 WÃ¶rter statt 2.000)
- Professionelle Tiefe statt generischer Content
- Recherchierte aktuelle Informationen
- Substantielle Use Cases und Praxisbeispiele

## ğŸ”§ Anpassungen

### Prompt anpassen

Bearbeite `scripts/generate-content.js`, Funktion `buildPrompt()`:

```javascript
function buildPrompt(transcript, userInstructions = '') {
  return `Du bist ein Experte fÃ¼r...

  # WICHTIGE ANFORDERUNGEN
  ...

  # DEINE AUFGABE
  ...`;
}
```

### Model wechseln

In `.env.local`:

```bash
OPENAI_MODEL=gpt-4o        # Standard (empfohlen)
OPENAI_MODEL=gpt-4-turbo   # Schneller, etwas gÃ¼nstiger
OPENAI_MODEL=gpt-4         # Original GPT-4
```

### Token-Limit anpassen

In `.env.local`:

```bash
OPENAI_MAX_TOKENS=24000  # Standard (neu: hÃ¶her fÃ¼r umfangreichere Artikel)
OPENAI_MAX_TOKENS=16000  # KÃ¼rzere Seiten
OPENAI_MAX_TOKENS=32000  # Sehr lange, detaillierte Seiten (teurer)
```

### Temperature anpassen

In `.env.local`:

```bash
OPENAI_TEMPERATURE=0.6   # Standard (neu: etwas niedriger fÃ¼r fachliche PrÃ¤zision)
OPENAI_TEMPERATURE=0.3   # Sehr deterministisch, faktisch
OPENAI_TEMPERATURE=0.8   # Etwas kreativer (aber nicht zu hoch fÃ¼r professionelle Inhalte)
```

## ğŸ“Š Workflow

### Kompletter Workflow: Von Transkript zu Published Page

1. **Transkript vorbereiten**
   ```bash
   # YouTube-Video transkribieren (mit Tools wie yt-dlp, whisper, etc.)
   # Oder: Manuelle Transkripte erstellen
   # Speichern in: transcripts/mein-video.txt
   ```

2. **Content generieren**
   ```bash
   npm run generate:interactive
   # Folge den Anweisungen
   ```

3. **Review & Anpassungen**
   ```bash
   # Ã–ffne die generierte Datei in deinem Editor
   code src/pages/GenerierteKomponente.tsx

   # PrÃ¼fe:
   # - Ist der Inhalt korrekt?
   # - Klingen die Texte authentisch?
   # - Sind die FAQs relevant?
   # - Funktionieren alle Links?
   ```

4. **Vorschau im Admin**
   ```bash
   npm run dev
   # Ã–ffne http://localhost:5173/admin
   # WÃ¤hle deinen Draft
   # Klicke "Vorschau"
   ```

5. **Feintuning (optional)**
   - Passe Formulierungen an
   - FÃ¼ge zusÃ¤tzliche Beispiele hinzu
   - Optimiere FAQ-Antworten
   - ErgÃ¤nze visuelle Elemente

6. **Commit & Push**
   ```bash
   git add .
   git commit -m "feat: Neue Wissensseite - [Titel]"
   git push
   ```

7. **Automatische Publikation**
   - GitHub Actions prÃ¼ft jeden Dienstag 9:00 Uhr
   - Draft mit `publishDate` <= heute wird automatisch published
   - Route wird in App.tsx hinzugefÃ¼gt
   - Seite ist live auf der Website

## ğŸ” Troubleshooting

### "OPENAI_API_KEY nicht gefunden"

**Problem**: .env.local existiert nicht oder ist falsch konfiguriert

**LÃ¶sung**:
```bash
# PrÃ¼fe, ob .env.local existiert
ls -la .env.local

# Falls nicht, erstelle sie
echo 'OPENAI_API_KEY=sk-proj-...' > .env.local
```

### "OpenAI API Error: Insufficient quota"

**Problem**: API Key hat kein Guthaben mehr

**LÃ¶sung**:
- Gehe zu https://platform.openai.com/account/billing
- FÃ¼ge Zahlungsmethode hinzu
- Lade Guthaben auf

### "Error: Cannot find module 'openai'"

**Problem**: Dependencies nicht installiert

**LÃ¶sung**:
```bash
npm install
```

### "Generated code is incomplete"

**Problem**: Token-Limit zu niedrig

**LÃ¶sung**:
```bash
# In .env.local erhÃ¶hen
OPENAI_MAX_TOKENS=20000
```

### "Content sounds too generic"

**Problem**: Prompt oder Temperature nicht optimal

**LÃ¶sung**:
- FÃ¼ge spezifischere Anweisungen hinzu im interaktiven Modus
- Senke Temperature auf 0.5 fÃ¼r faktischeren Output
- FÃ¼ge konkrete Beispiele aus dem Transkript als Context hinzu

## ğŸ“š Best Practices

### 1. Transkript-QualitÃ¤t

**Do's:**
- âœ… Strukturierte Transkripte mit klaren Abschnitten
- âœ… Wichtige Punkte hervorheben
- âœ… Technische Begriffe korrekt schreiben
- âœ… Zeitstempel fÃ¼r wichtige Stellen

**Don'ts:**
- âŒ Komplett unstrukturierte Wall of Text
- âŒ Viele FÃ¼llwÃ¶rter ("Ã¤hm", "also", etc.)
- âŒ Unklare oder fehlerhafte Begriffe

### 2. ZusÃ¤tzliche Anweisungen

**Effektive Anweisungen:**
```
"Fokus auf Enterprise-Features und Governance"
"Zielgruppe: IT-Administratoren, technisch versiert"
"Viele Code-Beispiele und API-Integrationen"
"Vergleich zu Konkurrenzprodukten wichtig"
```

**Weniger effektiv:**
```
"Mach es gut"
"Schreib viel"
"Sei kreativ"
```

### 3. Review-Checklist

Nach der Generierung prÃ¼fen:

- [ ] Titel und Description passend?
- [ ] Keywords relevant und vollstÃ¤ndig?
- [ ] Table of Contents sinnvoll strukturiert?
- [ ] FAQ-Fragen beantworten echte User-Fragen?
- [ ] Texte klingen authentisch, nicht AI-generiert?
- [ ] Technische Details korrekt?
- [ ] Links funktionieren?
- [ ] Schema.org Markup vollstÃ¤ndig?
- [ ] Call-to-Action am Ende sinnvoll?

### 4. Batch-Generierung

FÃ¼r mehrere Seiten:

```bash
# Erstelle Script fÃ¼r Batch-Processing
for transcript in transcripts/*.txt; do
  npm run generate "$transcript"
  sleep 5  # Pause zwischen API-Calls
done
```

## ğŸš€ Erweiterte Nutzung

### Custom Workflow mit Node.js

```javascript
import { generateContent, generateMetadata, saveContent } from './scripts/generate-content.js';

const transcript = `...dein Transkript...`;
const instructions = "Fokus auf Advanced Features";

// Generiere Content
const component = await generateContent(transcript, instructions);

// Generiere Metadaten
const metadata = generateMetadata(component, transcript);

// Passe Metadaten an
metadata.publishDate = "2025-12-01T09:00:00.000Z";
metadata.keywords.push("Custom Keyword");

// Speichern
saveContent(component, metadata);
```

### Integration in andere Tools

Das Script kann auch als Modul importiert werden:

```javascript
import { generateContent } from './scripts/generate-content.js';

// In deinem eigenen Tool
const content = await generateContent(myTranscript);
```

## ğŸ“ˆ Roadmap

Geplante Features:

- [ ] Web-UI fÃ¼r Content-Generierung (statt CLI)
- [ ] Batch-Processing mit Queue
- [ ] Multi-Model Support (GPT-4, Claude, Gemini)
- [ ] A/B-Testing: Multiple Varianten generieren
- [ ] SEO-Score-Berechnung fÃ¼r generierten Content
- [ ] Automatisches Image-Generation (DALL-E Integration)
- [ ] Direkte YouTube-Integration (URL â†’ Transkript â†’ Seite)
- [ ] Kosten-Tracking Dashboard

## ğŸ¤ Support

Bei Problemen oder Fragen:

1. PrÃ¼fe diese README
2. Schaue in die Logs (`console.log` Ausgaben)
3. Teste mit kleinerem Transkript
4. Kontaktiere das Team

---

**Happy Generating! ğŸ‰**
